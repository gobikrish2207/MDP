{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.utils import load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support, roc_curve, auc\nimport seaborn as sns\nimport random\nfrom glob import glob\nimport os\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading ","metadata":{}},{"cell_type":"code","source":"#global declarations\nIMAGE_WIDTH=128\nIMAGE_HEIGHT=128\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = r\"/kaggle/input/cell-images-for-detecting-malaria/\"\ntarget_classes = os.listdir(data_dir)\nprint(target_classes)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"infected_images     = glob(os.path.join(data_dir, target_classes[0])+\"/*.png\")\nuninfected_images   = glob(os.path.join(data_dir, target_classes[1])+\"/*.png\")\n\ndata = []\n\nfor image_path in (infected_images + uninfected_images): \n     \n        label = target_classes[0] if (target_classes[0] in image_path) else target_classes[1] \n        data.append((image_path, label))\n      \n\ndata_df = pd.DataFrame(data, columns=[\"image_path\", \"label\"])\ndata_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the counts for each class\nsample_count = data_df['label'].value_counts()\nprint(sample_count)\n\n# Plot the results \nplt.figure(figsize=(10,8))\nsns.barplot(x=sample_count.index, y= sample_count.values)\nplt.title('Number of cases', fontsize=14)\nplt.xlabel('Case type', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.xticks(range(len(sample_count.index)), ['Parasitized(1)', 'Uninfected(0)'])\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(18, 8))\nfig.suptitle('Parasitized cells', fontsize=24)\n\nfor ind, img_src in enumerate(infected_images[:30]):\n    plt.subplot(3, 10, ind+1)\n    img = plt.imread(img_src)\n    plt.axis('off')\n    plt.imshow(img)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(18, 8))\nfig.suptitle('Uninfected cells', fontsize=24)\n\nfor ind, img_src in enumerate(uninfected_images[:30]):\n    plt.subplot(3, 10, ind+1)\n    img = plt.imread(img_src)\n    plt.axis('off')\n    plt.imshow(img)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing data for training and validation","metadata":{}},{"cell_type":"code","source":"train_df, test_df = train_test_split(data_df, test_size=0.30, random_state=42)\ntrain_df, validate_df = train_test_split(train_df, test_size=0.20, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\ntotal_test = test_df.shape[0]\nbatch_size=16\nprint(f\"Total training samples : {len(train_df)}\\nTotal validation samples : {len(validate_df)}\\nTotal Test samples : {len(test_df)}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying Augmentation to genearate images with different angles, shift, flips etc.\ntrain_datagen = ImageDataGenerator(\n    rotation_range=15,\n    rescale=1./255,\n    shear_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.1,\n    height_shift_range=0.1\n)\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VGG 19","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nfrom tensorflow.keras.optimizers import  Adam\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.vgg16 import VGG16","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_vgg =  train_datagen.flow_from_dataframe(dataframe = train_df,  x_col='image_path', y_col='label',  class_mode='categorical',target_size=(224,224), shuffle=False, batch_size=10, seed=10)\nx_val_vgg = validation_datagen.flow_from_dataframe(dataframe = validate_df,  x_col='image_path', y_col='label',class_mode='categorical',  target_size=(224,224), shuffle=False, batch_size=10, seed=10)\n\nvgg19_model = VGG19(input_shape=(224,224,3), weights='imagenet',include_top=False)\nmodel=Sequential()\nmodel.add(vgg19_model)\nmodel.add(Flatten())\nmodel.add(Dense(1024,activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(2,activation='softmax'))\nmodel.compile(optimizer=Adam(learning_rate=1e-4),loss='categorical_crossentropy',metrics=['accuracy'])\n\nmodel_history = model.fit(\nx_train_vgg,\nsteps_per_epoch=100,\nvalidation_data=x_val_vgg,\nvalidation_steps=100, \nepochs = 10)\n    \n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize = (30, 10))\nax = ax.ravel()\n\nfor i, metric in enumerate([\"accuracy\", \"loss\"]):\n    ax[i].plot(model_history.history[metric])\n    ax[i].plot(model_history.history[\"val_\" + metric])\n    ax[i].set_title(\"Model {}\".format(metric))\n    ax[i].set_xlabel(\"Epochs\")\n    ax[i].set_ylabel(metric)\n    ax[i].legend([\"train\", \"val\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(x_val_vgg)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# validation loss = 0.69\n# validation Accuracy = ~50%","metadata":{}},{"cell_type":"markdown","source":"*Performs poor, maybe the model is too complex*","metadata":{}},{"cell_type":"markdown","source":"# VGG16","metadata":{}},{"cell_type":"code","source":"# Using the flow_from_dataframe method to generate batches of training data from a DataFrame\nx_train_vgg16 = train_datagen.flow_from_dataframe(\n    dataframe=train_df,                 \n    x_col='image_path',                 \n    y_col='label',                      \n    class_mode='binary',                \n    target_size=IMAGE_SIZE,             \n    shuffle=False,                     \n    batch_size=10,                      \n    seed=10                             \n)\n\n# Using the flow_from_dataframe method to generate batches of validation data from a DataFrame\nx_val_vgg16 = validation_datagen.flow_from_dataframe(\n    dataframe=validate_df,              \n    x_col='image_path',                 \n    y_col='label',                      \n    class_mode='binary',               \n    target_size=IMAGE_SIZE,             \n    shuffle=False,                     \n    batch_size=10,                      \n    seed=10                            \n)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" # Import VGG16 model and set its input shape to (128,128,3)\nvgg16 = VGG16(input_shape=(128,128,3), weights='imagenet', include_top=False) \n  \n\n# Freeze all the layers in the VGG16 model so that their weights will not be updated during training  \nfor layer in vgg16.layers:\n    layer.trainable = False\n\n# Add classification head\nx = Flatten()(vgg16.output)\nx = Dense(4096)(x)\nprediction = Dense(1, activation='sigmoid')(x)\n\nvgg16_model = Model(inputs=vgg16.input, outputs=prediction)\nvgg16_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the VGG16 model with Adam optimizer, binary crossentropy loss, and accuracy metric\nvgg16_model.compile(optimizer='adam',\n              loss=['binary_crossentropy'],\n              metrics=[\"accuracy\"])\n\nhistory_vgg16 = vgg16_model.fit(x_train_vgg16,\n                    epochs =30,\n                    steps_per_epoch=100,\n                    validation_data = x_val_vgg16,\n                    validation_steps=100, \n                    batch_size=10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize = (30, 10))\nax = ax.ravel()\n\nfor i, metric in enumerate([\"accuracy\", \"loss\"]):\n    ax[i].plot(history_vgg16.history[metric])\n    ax[i].plot(history_vgg16.history[\"val_\" + metric])\n    ax[i].set_title(\"Model {}\".format(metric))\n    ax[i].set_xlabel(\"Epochs\")\n    ax[i].set_ylabel(metric)\n    ax[i].legend([\"train\", \"val\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_model.evaluate(x_val_vgg16)   # evaluation on validation set","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation loss = 0.26\n\n# Validation Accuracy = ~ 90.6 %","metadata":{}},{"cell_type":"markdown","source":"*The VGG19 model has lower accuracy compared to the VGG16 model, possibly due to its deeper architecture which may lead to overfitting and slower training. On the other hand, the VGG16 model has fewer layers and is pretrained on a larger dataset, resulting in better feature extraction capabilities and better generalization performance. Therefore, we have an insight here that it is not always the case that a deeper model will perform better, as it depends on the specific dataset.*","metadata":{}},{"cell_type":"markdown","source":"# CUSTOM CNN ARCHITECTURE","metadata":{}},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_dataframe(\n    train_df,  \n    x_col='image_path',\n    y_col='label',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=16\n)\n\nvalidation_generator = validation_datagen.flow_from_dataframe(\n    validate_df, \n    x_col='image_path',\n    y_col='label',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=16\n)\n\n\n\ntotal_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\ntotal_test = test_df.shape[0]\nbatch_size=16\n\nprint(f\"Training data : {total_train}\\nvalidation data : {total_validate}\\nTest data : {total_test}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\nfrom tensorflow.keras.optimizers import  RMSprop\n\n\n# Define a sequential model\nmodel = Sequential()\n\n# Add convolutional layer with 32 filters, kernel size of (3,3), ReLU activation, and input shape\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n# Add max pooling layer with pool size of (2,2)\nmodel.add(MaxPooling2D(pool_size=(2, 2)))                                                                                   # CONV BLOCK 1\n# Add batch normalization layer\nmodel.add(BatchNormalization())\n\n# Add convolutional layer with 32 filters, kernel size of (3,3), ReLU activation\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\n# Add max pooling layer with pool size of (2,2)\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# Add batch normalization layer                                                                                               # CONV BLOCK 2\nmodel.add(BatchNormalization())\n# Add dropout layer with a rate of 0.5\nmodel.add(Dropout(0.5))\n\n# Add convolutional layer with 64 filters, kernel size of (3,3), ReLU activation\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\n# Add batch normalization layer\nmodel.add(BatchNormalization())\n# Add max pooling layer with pool size of (2,2)                                                                              # CONV BLOCK 3\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# Add dropout layer with a rate of 0.25\nmodel.add(Dropout(0.25))\n\n# Add flatten layer\nmodel.add(Flatten())\n\n# Add dense layer with 128 units and ReLU activation\nmodel.add(Dense(128, activation='relu'))\n# Add dropout layer with a rate of 0.5\nmodel.add(Dropout(0.5))                                                                                                     # CLASSIFICATION HEAD\n# Add dense layer with 2 units and softmax activation\nmodel.add(Dense(2, activation='softmax')) \n\n# Define optimizer as RMSprop with learning rate of 0.0001\noptimizer = RMSprop(learning_rate=0.0001)\n\n# Compile model with categorical crossentropy loss and accuracy metric\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\n# Print model summary\nmodel.summary()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the model and train for 30 epochs\nepochs = 30\nhistory = model.fit_generator(\n    train_generator, \n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=total_validate//batch_size,\n    steps_per_epoch=total_train//batch_size\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize = (30, 10))\nax = ax.ravel()\n\nfor i, metric in enumerate([\"accuracy\", \"loss\"]):\n    ax[i].plot(history.history[metric])\n    ax[i].plot(history.history[\"val_\" + metric])\n    ax[i].set_title(\"Model {}\".format(metric))\n    ax[i].set_xlabel(\"Epochs\")\n    ax[i].set_ylabel(metric)\n    ax[i].legend([\"train\", \"val\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(validation_generator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation loss = 0.185\n\n# Validation Accuracy = ~ 95 %","metadata":{}},{"cell_type":"markdown","source":"*Supporting our previous insight that for our dataset, a simpler architecture works better than a complex one as vgg19. When compared to vgg16 which performed signifcantly better than vgg19, The custom CNN, despite its simpler architecture, has achieved a high validation accuracy of 95%, which is comparable to the VGG16 model's accuracy of 90%.*\n\n*By looking at the loss & accuracy curves, we can observe some sudden steeps. This indicates that there is some noise out there which hinders the model's convergance at regular intervals. Now, we look forward to tune the performance of this custom cnn model and get smooth training curves with hopefully a lesser loss and higher accuracy*","metadata":{}},{"cell_type":"markdown","source":"# Tuning the CNN","metadata":{}},{"cell_type":"code","source":"batch_size=16\nx_train_tuned_cnn =  train_datagen.flow_from_dataframe(\ndataframe = train_df,\nx_col='image_path',\ny_col='label',\nclass_mode='categorical',\ntarget_size=IMAGE_SIZE,\nshuffle=False,\nbatch_size=batch_size,\nseed=10)\n\n\n\nx_val_tuned_cnn = validation_datagen.flow_from_dataframe(\ndataframe = validate_df,\nx_col='image_path',\ny_col='label',\nclass_mode='categorical',\ntarget_size=IMAGE_SIZE,\nshuffle=False,\nbatch_size=batch_size,\nseed=10)\n\ntotal_train = train_df.shape[0]\ntotal_validate = validate_df.shape[0]\ntotal_test = test_df.shape[0]\nbatch_size=16\n\nprint(f\"Training data : {total_train}\\nvalidation data : {total_validate}\\nTest data : {total_test}\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a sequential model\ntuned_model = Sequential()\n\n# Add the first convolutional layer with 16 filters and a 3x3 kernel\ntuned_model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n# Add max pooling layer with a 2x2 pool size\ntuned_model.add(MaxPooling2D(pool_size=(2, 2)))                                                                         # CONV BLOCK 1\n# Add dropout layer with a rate of 0.2\ntuned_model.add(Dropout(0.2))\n\n# Add second convolutional layer with 32 filters and a 3x3 kernel\ntuned_model.add(Conv2D(32, (3, 3), activation='relu'))\n# Add max pooling layer with a 2x2 pool size                                                                            # CONV BLOCK 2\ntuned_model.add(MaxPooling2D(pool_size=(2, 2)))\n# Add dropout layer with a rate of 0.25\ntuned_model.add(Dropout(0.25))\n\n# Add third convolutional layer with 64 filters and a 3x3 kernel\ntuned_model.add(Conv2D(64, (3, 3), activation='relu'))\n# Add max pooling layer with a 2x2 pool size                                                                            # CONV BLOCK 3\ntuned_model.add(MaxPooling2D(pool_size=(2, 2)))\n# Add dropout layer with a rate of 0.25\ntuned_model.add(Dropout(0.25))\n\n# Add flatten layer to convert the output from 2D to 1D\ntuned_model.add(Flatten())\n\n# Add a fully connected layer with 1024 units and ReLU activation\ntuned_model.add(Dense(1024, activation='relu'))                                                                         # CLASSIFICATION HEAD\n# Add batch normalization layer\ntuned_model.add(BatchNormalization())\n# Add dropout layer with a rate of 0.5\ntuned_model.add(Dropout(0.5))\n\n# Add a fully connected layer with 512 units and ReLU activation\ntuned_model.add(Dense(512, activation='relu'))\n# Add batch normalization layer\ntuned_model.add(BatchNormalization())\n# Add dropout layer with a rate of 0.5\ntuned_model.add(Dropout(0.5))\n\n# Add a fully connected layer with 128 units and ReLU activation\ntuned_model.add(Dense(128, activation='relu'))\n# Add batch normalization layer\ntuned_model.add(BatchNormalization())\n# Add dropout layer with a rate of 0.5\ntuned_model.add(Dropout(0.5))\n\n# Add output layer with 2 units and softmax activation for binary classification\ntuned_model.add(Dense(2, activation='softmax')) \n\n# Define Adam optimizer with a learning rate of 0.0001\noptimizer = Adam(learning_rate=0.0001)\n\n# Compile the model with categorical crossentropy loss and accuracy metric\ntuned_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\n# Print the model summary\ntuned_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuned_model.compile(loss = \"categorical_crossentropy\" , optimizer = \"adam\" , metrics = [\"accuracy\"])\ntuned_model_history = tuned_model.fit_generator(\n    x_train_tuned_cnn, \n    epochs=30,\n    validation_data=x_val_tuned_cnn,\n    validation_steps=total_validate//batch_size,\n    steps_per_epoch=total_train//batch_size\n)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize = (30, 10))\nax = ax.ravel()\n\nfor i, metric in enumerate([\"accuracy\", \"loss\"]):\n    ax[i].plot(tuned_model_history.history[metric])\n    ax[i].plot(tuned_model_history.history[\"val_\" + metric])\n    ax[i].set_title(\"Model {}\".format(metric))\n    ax[i].set_xlabel(\"Epochs\")\n    ax[i].set_ylabel(metric)\n    ax[i].legend([\"train\", \"val\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Observastion : The Accuracy and loss curves are now way smoother than the earlier model*","metadata":{}},{"cell_type":"code","source":"tuned_model.evaluate(x_val_tuned_cnn)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation loss = 0.13\n\n# Validation Accuracy = ~ 96 %","metadata":{}},{"cell_type":"markdown","source":"- Induced the feature pyramid culture by decreasing the no. of filters in the initial convolutional layers and added more dense layers in the classification head, resulting in a more powerful model with increased capacity for feature extraction and classification.\n- Reduced the dropout rate in the initial layers to retain more information from the input, allowing the model to learn more effectively from the data.\n- Changed the optimizer from RMSprop to Adam, which is known to perform well on a wide range of deep learning tasks, resulting in better optimization and faster convergence of the training process.","metadata":{}},{"cell_type":"markdown","source":"# Evaluation using various metrics on test set","metadata":{}},{"cell_type":"code","source":"test_gen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_gen.flow_from_dataframe(\n    test_df, \n    x_col='image_path',\n    y_col='label',\n    class_mode='categorical',\n    target_size=IMAGE_SIZE,\n    batch_size=batch_size,\n    shuffle=False\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make predictions using the model\ny_pred = tuned_model.predict_generator(test_generator, steps=test_generator.samples)\n\n# get the true labels\ny_true = test_generator.classes\n\n# get the class indices\nclass_indices = test_generator.class_indices\n\n# get the class names\nclass_names = list(class_indices.keys())\n\n# get the predicted labels\ny_pred = np.argmax(y_pred, axis=1)\n\n# create the confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# print the confusion matrix\nprint(cm)\n\n# plot the confusion matrix\n# create a heatmap of the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, cmap='Blues', fmt='g', xticklabels=class_indices.keys(), yticklabels=class_indices.keys())\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show()\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cost matrix Readings\n\nTP = 3901, TN = 4096, FP = 116, FN = 245","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_true, y_pred, target_names=class_names))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate precision, recall, f1 score, and support\nprecision, recall, f1_score, support = precision_recall_fscore_support(y_true, y_pred)\n\n# plot precision, recall, and f1 score\nfig, ax = plt.subplots()\nx_labels = list(class_indices.keys())\nx_pos = np.arange(len(x_labels))\nax.bar(x_pos - 0.2, precision, width=0.2, label='Precision')\nax.bar(x_pos, recall, width=0.2, label='Recall')\nax.bar(x_pos + 0.2, f1_score, width=0.2, label='F1 Score')\nax.set_xticks(x_pos)\nax.set_xticklabels(x_labels)\nax.set_ylim([0, 1])\nax.set_xlabel('Class')\nax.set_ylabel('Score')\nax.set_title('Precision, Recall, and F1 Score')\nax.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Precision: It is the ratio of true positives to the sum of true positives and false positives. In other words, it measures the proportion of positive predictions that were actually correct. For the class \"Parasitized\", the precision is 0.97, which means that 97% of the images predicted as \"Parasitized\" were actually Parasitized. Similarly, for the class \"Uninfected\", the precision is 0.94, which means that 94% of the images predicted as \"Uninfected\" were actually Uninfected.\n- Recall: It is the ratio of true positives to the sum of true positives and false negatives. In other words, it measures the proportion of actual positives that were correctly identified. For the class \"Parasitized\", the recall is 0.94, which means that 94% of the actual Parasitized images were correctly identified as Parasitized. Similarly, for the class \"Uninfected\", the recall is 0.97, which means that 97% of the actual Uninfected images were correctly identified as Uninfected.\n- F1-score: It is the harmonic mean of precision and recall, and provides a single score that balances both these metrics. For both the classes, the F1-score is 0.96, which means that the model is performing equally well on both the classes.\n- Support: It is the number of samples in each class.\n\nIn summary, the model is performing well with an overall accuracy of 0.96, and good precision, recall and F1-score for both the classes.\n\n","metadata":{}},{"cell_type":"code","source":"# calculate the ROC curve\nfpr, tpr, thresholds = roc_curve(y_true, y_pred)\n\n# calculate the AUC ROC\nauc_score = auc(fpr, tpr)\n\n# plot the ROC curve\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc=\"lower right\")\n\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The area under the receiver operating characteristic (ROC) curve for the model is 0.96, indicating that the model has good predictive performance.","metadata":{}}]}